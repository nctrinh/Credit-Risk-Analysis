{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c60d4b-a3df-48f4-8a00-0492435ba426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611db6c0-616e-4c6e-9359-bbfcf8c5d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, count, round, when, countDistinct as _round\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.functions import vector_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d2ca71-2102-490e-95dd-c390c8f31b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"FeatureExtraction\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f53d45-7355-4b0e-aaa1-ad2b77de1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_schema = StructType([\n",
    "    StructField(\"initial_list_status_w\", IntegerType(), nullable=False),\n",
    "    StructField(\"last_pymnt_amnt\", DoubleType(), nullable=True),\n",
    "    StructField(\"out_prncp\", DoubleType(), nullable=True),\n",
    "    StructField(\"loan_amnt\", DoubleType(), nullable=True),\n",
    "    StructField(\"int_rate\", DoubleType(), nullable=True),\n",
    "    StructField(\"is_60_months\", IntegerType(), nullable=False),\n",
    "    StructField(\"purpose_debt_consolidation\", IntegerType(), nullable=False),\n",
    "    StructField(\"purpose_credit_card\", IntegerType(), nullable=False),\n",
    "    StructField(\"purpose_home_improvement\", IntegerType(), nullable=False),\n",
    "    StructField(\"purpose_major_purchase\", IntegerType(), nullable=False),\n",
    "    StructField(\"purpose_small_business\", IntegerType(), nullable=False),\n",
    "    StructField(\"purpose_car\", IntegerType(), nullable=False),\n",
    "    StructField(\"purpose_medical\", IntegerType(), nullable=False),\n",
    "    StructField(\"purpose_other\", IntegerType(), nullable=False),\n",
    "    StructField(\"total_pymnt\", DoubleType(), nullable=True),\n",
    "    StructField(\"total_rec_int\", DoubleType(), nullable=True),\n",
    "    StructField(\"total_rec_late_fee\", DoubleType(), nullable=True),\n",
    "    StructField(\"recoveries\", DoubleType(), nullable=True),\n",
    "    StructField(\"delinq_2yrs\", DoubleType(), nullable=True),\n",
    "    StructField(\"inq_last_6mths\", DoubleType(), nullable=True),\n",
    "    StructField(\"mths_since_last_delinq\", DoubleType(), nullable=True),\n",
    "    StructField(\"mths_since_last_record\", DoubleType(), nullable=True),\n",
    "    StructField(\"open_acc\", DoubleType(), nullable=True),\n",
    "    StructField(\"pub_rec\", DoubleType(), nullable=True),\n",
    "    StructField(\"revol_util\", DoubleType(), nullable=True),\n",
    "    StructField(\"total_acc\", DoubleType(), nullable=True),\n",
    "    StructField(\"collections_12_mths_ex_med\", DoubleType(), nullable=True),\n",
    "    StructField(\"mths_since_last_major_derog\", DoubleType(), nullable=True),\n",
    "    StructField(\"open_acc_6m\", DoubleType(), nullable=True),\n",
    "    StructField(\"open_il_24m\", DoubleType(), nullable=True),\n",
    "    StructField(\"mths_since_rcnt_il\", DoubleType(), nullable=True),\n",
    "    StructField(\"total_bal_il\", DoubleType(), nullable=True),\n",
    "    StructField(\"open_rv_24m\", DoubleType(), nullable=True),\n",
    "    StructField(\"all_util\", DoubleType(), nullable=True),\n",
    "    StructField(\"total_rev_hi_lim\", DoubleType(), nullable=True),\n",
    "    StructField(\"tot_coll_amt\", DoubleType(), nullable=True),\n",
    "    StructField(\"tot_cur_bal\", DoubleType(), nullable=True),\n",
    "    StructField(\"inq_fi\", DoubleType(), nullable=True),\n",
    "    StructField(\"total_cu_tl\", DoubleType(), nullable=True),\n",
    "    StructField(\"inq_last_12m\", DoubleType(), nullable=True),\n",
    "    StructField(\"annual_inc\", DoubleType(), nullable=True),\n",
    "    StructField(\"emp_length_num\", DoubleType(), nullable=False),\n",
    "    StructField(\"is_mortgage\", IntegerType(), nullable=False),\n",
    "    StructField(\"is_rent\", IntegerType(), nullable=False),\n",
    "    StructField(\"is_own\", IntegerType(), nullable=False),\n",
    "    StructField(\"is_source_verified\", IntegerType(), nullable=False),\n",
    "    StructField(\"is_verified\", IntegerType(), nullable=False),\n",
    "    StructField(\"is_not_verified\", IntegerType(), nullable=False),\n",
    "    StructField(\"loan_status_label\", IntegerType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5613642-122b-41bf-8d1a-5cf0d48c2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .option(\"quote\", '\"')\n",
    "    .option(\"escape\", '\"')\n",
    "    .schema(final_schema)\n",
    "    .csv(\"hdfs://namenode:9000/bigdata/data/final_data\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0452411c-c39f-41b7-bbaf-148b14965d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = \"loan_status_label\"\n",
    "\n",
    "feature_cols = [c for c in df.columns if c != label_col]\n",
    "\n",
    "train_df, test_df = df.randomSplit([0.85, 0.15], seed=42)\n",
    "X_train_df, Y_train_df = train_df.select(*feature_cols), train_df.select(label_col)\n",
    "X_test_df, Y_test_df = test_df.select(*feature_cols), test_df.select(label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d3553-a0e3-4afd-add1-0d62bb41309d",
   "metadata": {},
   "source": [
    "# I. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80871c68-520a-46a1-86db-8083fe792bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in feature_cols:\n",
    "#     n_unique = X_train_df.select(c).distinct().count()\n",
    "    \n",
    "#     if n_unique <= 12:\n",
    "#         print(f\"Column: {c}, Unique values: {n_unique}\")\n",
    "#         unique_vals = [row[c] for row in df.select(c).distinct().collect()]\n",
    "#         print(f\"  Values: {unique_vals}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a946f9-1375-4026-b2f5-09a23be36bc7",
   "metadata": {},
   "source": [
    "### Như vậy, các cột có loại dữ liệu Categorical là:\n",
    "`initial_list_status_w`, `initial_list_status_w`, `purpose_debt_consolidation`, `purpose_credit_card`, `purpose_home_improvement`, `purpose_major_purchase`, `purpose_small_business`, `purpose_car`, `purpose_medical`, `purpose_other`, `is_mortgage`, `is_rent`, `is_own`, `is_source_verified`, `is_verified`, `is_not_verified`, `emp_length_num`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb76f06-e23e-4939-9bb6-b92ecfcc4ffb",
   "metadata": {},
   "source": [
    "### Với các cột còn lại, loại dữ liệu là Numerical, sẽ cần xem phân phối dữ liệu và kiểm tra outlier để lựa chọn phương pháp scale phù hợp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "641b624c-c24a-431d-b293-f44998e3163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [\n",
    "    'initial_list_status_w', 'is_60_months', 'purpose_debt_consolidation', 'purpose_credit_card',\n",
    "    'purpose_home_improvement', 'purpose_major_purchase', 'purpose_small_business',\n",
    "    'purpose_car', 'purpose_medical', 'purpose_other', \n",
    "    'is_mortgage', 'is_rent', 'is_own', \n",
    "    'is_source_verified', 'is_verified', 'is_not_verified', 'emp_length_num'\n",
    "]\n",
    "\n",
    "numeric_cols = [c for c in feature_cols if c not in exclude_cols]\n",
    "\n",
    "# for col in numeric_cols:\n",
    "#     data = X_train_df.select(col).toPandas()[col]\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(9, 3))\n",
    "\n",
    "#     # Histogram\n",
    "#     axes[0].hist(data, bins=30, color='skyblue', edgecolor='black')\n",
    "#     axes[0].set_title(f'Histogram of {col}')\n",
    "    \n",
    "#     # Boxplot\n",
    "#     axes[1].boxplot(data, vert=False)\n",
    "#     axes[1].set_title(f'Boxplot of {col}')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64698a34-8cb1-4c37-99d9-9679ae1e12b5",
   "metadata": {},
   "source": [
    "### Có thể thấy hầu hết các cột đều có phân phối lệch, ngoại trừ `loan_amnt`. Vì vậy, để chuẩn hóa giá trị trong các cột, sẽ sử dụng: Log_Transform + Standard_Scaler cho các cột phân phối lệch; với cột phân phối không lệch thì sẽ sử dụng Standard_Scaler để chuẩn hóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a229506a-2156-4309-8c86-9f3248b22905",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = [c for c in numeric_cols if c != 'loan_amnt']\n",
    "unskewed_cols = ['loan_amnt']\n",
    "has_neg_cols = ['mths_since_last_delinq', 'mths_since_last_record', 'mths_since_last_major_derog']\n",
    "categorical_cols = [\n",
    "    'initial_list_status_w', 'is_60_months', 'purpose_debt_consolidation', 'purpose_credit_card',\n",
    "    'purpose_home_improvement', 'purpose_major_purchase', 'purpose_small_business',\n",
    "    'purpose_car', 'purpose_medical', 'purpose_other', \n",
    "    'is_mortgage', 'is_rent', 'is_own', \n",
    "    'is_source_verified', 'is_verified', 'is_not_verified', 'emp_length_num'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d5dd73-09ca-4f5d-a15e-9d728d11f191",
   "metadata": {},
   "source": [
    "#### Log-transform cho các cột lệch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "331b3cba-bfbd-47de-bb22-261ac2547815",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in skewed_cols:\n",
    "    X_train_df = X_train_df.withColumn(c, F.log1p(F.col(c)))\n",
    "    X_test_df = X_test_df.withColumn(c, F.log1p(F.col(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb80bdb8-777d-4a80-bfec-01b40b32e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=skewed_cols + unskewed_cols,\n",
    "    outputCol=\"features_unscaled\"\n",
    ")\n",
    "train_vec = assembler.transform(X_train_df)\n",
    "test_vec = assembler.transform(X_test_df)\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features_unscaled\",\n",
    "    outputCol=\"features_scaled\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "scaler_model = scaler.fit(train_vec)\n",
    "train_scaled = scaler_model.transform(train_vec)\n",
    "test_scaled = scaler_model.transform(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0544de55-483c-4ec0-bc94-6133c13978f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_scaled.select(\"features_scaled\", *categorical_cols)\n",
    "X_test_df = test_scaled.select(\"features_scaled\", *categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8413b804-ffd4-4c20-8d48-61d3bc3dfcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features_scaled=DenseVector([-3.8986, -1.5484, 1.1811, -4.9467, -4.4176, -0.1178, -0.1654, -0.4492, 1.4436, 1.1555, -0.4221, -0.3442, -0.4041, -5.9411, 1.4006, -0.1135, -0.5672, -0.1154, -0.1258, -0.1444, -0.1468, -0.1359, -0.1554, -0.3619, -0.3761, 0.1248, -0.0989, -0.0962, -0.1251, 0.7322, -1.506]), initial_list_status_w=0, is_60_months=0, purpose_debt_consolidation=1, purpose_credit_card=0, purpose_home_improvement=0, purpose_major_purchase=0, purpose_small_business=0, purpose_car=0, purpose_medical=0, purpose_other=0, is_mortgage=0, is_rent=1, is_own=0, is_source_verified=0, is_verified=1, is_not_verified=0, emp_length_num=10.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a05b5ce9-6cb8-4951-b7a9-3b4db9c653a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(loan_status_label=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44775408-0cb3-4843-b7f4-9b27479b58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_model(X_df, Y_df):\n",
    "    df = X_df.withColumn(\"features_array\", vector_to_array(\"features_scaled\"))\n",
    "    \n",
    "    extra_cols = [\n",
    "        \"initial_list_status_w\", \"is_60_months\",\n",
    "        \"purpose_debt_consolidation\", \"purpose_credit_card\", \"purpose_home_improvement\",\n",
    "        \"purpose_major_purchase\", \"purpose_small_business\", \"purpose_car\", \"purpose_medical\",\n",
    "        \"purpose_other\", \"is_mortgage\", \"is_rent\", \"is_own\",\n",
    "        \"is_source_verified\", \"is_verified\", \"is_not_verified\",\n",
    "        \"emp_length_num\"\n",
    "    ]\n",
    "    \n",
    "    arrays = [F.col(\"features_array\")] + [F.array(F.col(c)) for c in extra_cols]\n",
    "    df = df.withColumn(\"all_features\", reduce(lambda x, y: F.concat(x, y), arrays))\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    x_iter = df.select(\"all_features\").toLocalIterator()\n",
    "    y_iter = Y_df.toLocalIterator()\n",
    "    \n",
    "    n_rows = df.count()\n",
    "    \n",
    "    for row_x, row_y in tqdm(\n",
    "        zip(x_iter, y_iter),\n",
    "        total=n_rows,\n",
    "        desc=\"Preparing data\"\n",
    "    ):\n",
    "        X_list.append(row_x[\"all_features\"])\n",
    "        y_list.append(row_y[\"loan_status_label\"])\n",
    "\n",
    "    X = np.array(X_list, dtype=np.float32)\n",
    "    y = np.array(y_list, dtype=np.float32)\n",
    "\n",
    "    \n",
    "    # X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    # y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    return {\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        # \"X_tensor\": X_tensor,\n",
    "        # \"y_tensor\": y_tensor\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fb09f24-99ec-4cfd-8a61-c4f67b52b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|██████████| 753510/753510 [00:38<00:00, 19365.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = prepare_data_for_model(X_train_df, Y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d402eb-812b-4c4e-9914-071f4d9e789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|██████████| 132799/132799 [00:15<00:00, 8405.95it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = prepare_data_for_model(X_test_df, Y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e42bf1c-0d93-4177-ad24-a18e6a534a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "Shape: (753510, 48)\n",
      "Dtype: float32\n",
      "\n",
      "\n",
      "y_train info:\n",
      "Shape: (753510,)\n",
      "Dtype: float32\n",
      "\n",
      "\n",
      "X_test info:\n",
      "Shape: (132799, 48)\n",
      "Dtype: float32\n",
      "\n",
      "\n",
      "y_test info:\n",
      "Shape: (132799,)\n",
      "Dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# X_train\n",
    "print(\"X_train info:\")\n",
    "print(f\"Shape: {train_data['X'].shape}\")\n",
    "print(f\"Dtype: {train_data['X'].dtype}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# y_train\n",
    "print(\"y_train info:\")\n",
    "print(f\"Shape: {train_data['y'].shape}\")\n",
    "print(f\"Dtype: {train_data['y'].dtype}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# X_test\n",
    "print(\"X_test info:\")\n",
    "print(f\"Shape: {test_data['X'].shape}\")\n",
    "print(f\"Dtype: {test_data['X'].dtype}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# y_test\n",
    "print(\"y_test info:\")\n",
    "print(f\"Shape: {test_data['y'].shape}\")\n",
    "print(f\"Dtype: {test_data['y'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8950225-3035-4b43-aaf3-73647097e24d",
   "metadata": {},
   "source": [
    "# II. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4cd766-913e-4cf2-9376-725ae7d39bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': array([[-3.8985558 , -1.5484096 ,  1.181145  , ...,  1.        ,\n",
       "          0.        , 10.        ],\n",
       "        [-3.8985558 , -1.5484096 ,  0.01006276, ...,  0.        ,\n",
       "          1.        ,  5.        ],\n",
       "        [-3.8985558 , -1.5484096 ,  0.31381395, ...,  0.        ,\n",
       "          1.        , 10.        ],\n",
       "        ...,\n",
       "        [ 2.5383134 , -1.5484096 , -0.12208486, ...,  1.        ,\n",
       "          0.        , 10.        ],\n",
       "        [ 2.543024  , -1.5484096 ,  0.8875873 , ...,  1.        ,\n",
       "          0.        ,  2.        ],\n",
       "        [ 2.545331  , -1.5484096 ,  1.7928197 , ...,  1.        ,\n",
       "          0.        ,  8.        ]], dtype=float32),\n",
       " 'y': array([0., 0., 0., ..., 1., 1., 1.], dtype=float32)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f79632b-eb2f-4fa8-bbe3-628cd631d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3cbc4d5-a086-4d82-b0f0-e3b31c3fdb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 38 epochs took 21 seconds\n",
      "AUC: 0.9327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   22.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.871     0.674     0.760     10213\n",
      "         1.0      0.973     0.992     0.982    122586\n",
      "\n",
      "    accuracy                          0.967    132799\n",
      "   macro avg      0.922     0.833     0.871    132799\n",
      "weighted avg      0.966     0.967     0.965    132799\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['logistic_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "X_train = train_data[\"X\"]\n",
    "y_train = train_data[\"y\"]\n",
    "\n",
    "X_test =  test_data['X']\n",
    "y_test = test_data['y']\n",
    "\n",
    "# Huấn luyện logistic regression \n",
    "model = LogisticRegression(\n",
    "    solver=\"saga\",          \n",
    "    max_iter=500,\n",
    "    penalty=\"l2\",\n",
    "    C=1.0,                 \n",
    "    n_jobs=-1,              \n",
    "    verbose=1              \n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Đánh giá\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "# Lưu mô hình\n",
    "joblib.dump(model, \"logistic_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83287e41-5ad9-446d-8435-78b1bde69b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b453c-7d64-4f6d-aafc-40ed5609cdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
